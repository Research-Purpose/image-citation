{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stack Overflow Question Generation using LLMs\n",
    "\n",
    "This notebook combines processing using different LLMs:\n",
    "- Google's Gemini\n",
    "- Meta's LLaMA\n",
    "- OpenAI's GPT\n",
    "\n",
    "Each section implements different prompting techniques:\n",
    "- Zero-shot/In-context\n",
    "- Few-shot\n",
    "- Chain-of-thoughts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import base64\n",
    "import pathlib\n",
    "import warnings\n",
    "import http.client\n",
    "import typing\n",
    "import urllib.request\n",
    "from PIL import Image, ImageOps, ImageDraw, ImageFont\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import io\n",
    "import numpy as np\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from groq import Groq\n",
    "from vertexai.generative_models import GenerationConfig, GenerativeModel, Image, Part\n",
    "import vertexai\n",
    "import openai\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from urllib3.exceptions import InsecureRequestWarning\n",
    "warnings.filterwarnings('ignore', category=InsecureRequestWarning)\n",
    "\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize environment variables and APIs\n",
    "load_dotenv()\n",
    "\n",
    "# Vertex AI initialization\n",
    "project_id = os.getenv('VERTEXAI_PROJECT_ID')\n",
    "vertexai.init(project=project_id, location=\"us-central1\")\n",
    "text_model = GenerativeModel(\"gemini-1.5-pro\")\n",
    "\n",
    "# OpenAI initialization\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Groq initialization\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')\n",
    "groq_client = Groq(api_key=groq_api_key)\n",
    "\n",
    "# Create output directories maintaining original structure\n",
    "OUTPUT_DIR = pathlib.Path('Data')\n",
    "GEMINI_DIR = OUTPUT_DIR / 'Gemini'\n",
    "LLAMA_DIR = OUTPUT_DIR / 'llama-3.2'\n",
    "GPT_DIR = OUTPUT_DIR / 'gpt-4'\n",
    "\n",
    "# Create directories if they don't exist\n",
    "for dir_path in [GEMINI_DIR, LLAMA_DIR, GPT_DIR]:\n",
    "    dir_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def create_similarity_directories():\n",
    "    \"\"\"Create directories for similarity analysis results\"\"\"\n",
    "    for base_dir in [GEMINI_DIR, LLAMA_DIR, GPT_DIR]:\n",
    "        similarity_dir = base_dir / 'similarity_analysis'\n",
    "        similarity_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Call this after your existing directory creation\n",
    "create_similarity_directories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "def encode_image_to_base64(image_url):\n",
    "    \"\"\"Convert image to base64 string\"\"\"\n",
    "    response = requests.get(image_url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "    response.raise_for_status()\n",
    "    return base64.b64encode(response.content).decode('utf-8')\n",
    "\n",
    "def resize_image(image, max_dimension):\n",
    "    \"\"\"Resize image maintaining aspect ratio\"\"\"\n",
    "    width, height = image.size\n",
    "    if image.mode == \"P\":\n",
    "        if \"transparency\" in image.info:\n",
    "            image = image.convert(\"RGBA\")\n",
    "        else:\n",
    "            image = image.convert(\"RGB\")\n",
    "    if width > max_dimension or height > max_dimension:\n",
    "        if width > height:\n",
    "            new_width = max_dimension\n",
    "            new_height = int(height * (max_dimension / width))\n",
    "        else:\n",
    "            new_height = max_dimension\n",
    "            new_width = int(width * (max_dimension / height))\n",
    "        image = image.resize((new_width, new_height), Image.LANCZOS)\n",
    "    return image\n",
    "\n",
    "def process_image(image_url, max_size):\n",
    "    \"\"\"Process image from URL\"\"\"\n",
    "    try:\n",
    "        response = requests.get(image_url)\n",
    "        response.raise_for_status()\n",
    "        image_data = io.BytesIO(response.content)\n",
    "\n",
    "        with Image.open(image_data) as image:\n",
    "            width, height = image.size\n",
    "            mimetype = image.get_format_mimetype()\n",
    "\n",
    "            if mimetype != \"image/png\" or width > max_size or height > max_size:\n",
    "                resized_image = resize_image(image, max_size)\n",
    "                png_data = io.BytesIO()\n",
    "                resized_image.save(png_data, format=\"PNG\")\n",
    "                return base64.b64encode(png_data.getvalue()).decode('utf-8')\n",
    "            else:\n",
    "                return base64.b64encode(response.content).decode('utf-8')\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image: {e}\")\n",
    "        return None\n",
    "\n",
    "def combine_images_vertical(images, max_size):\n",
    "    \"\"\"Combine multiple images into a vertical collage with labels\"\"\"\n",
    "    processed_images = []\n",
    "    for img_url in images:\n",
    "        processed = process_image(img_url, max_size)\n",
    "        if processed:\n",
    "            processed_images.append(processed)\n",
    "\n",
    "    if not processed_images:\n",
    "        return None\n",
    "\n",
    "    pil_images = []\n",
    "    for img_data in processed_images:\n",
    "        try:\n",
    "            img_bytes = base64.b64decode(img_data)\n",
    "            img = Image.open(io.BytesIO(img_bytes))\n",
    "            pil_images.append(img)\n",
    "        except Exception as e:\n",
    "            print(f\"Error converting base64 to image: {e}\")\n",
    "            continue\n",
    "\n",
    "    if not pil_images:\n",
    "        return None\n",
    "\n",
    "    max_width = max(img.width for img in pil_images)\n",
    "    total_height = sum(img.height for img in pil_images) + (len(pil_images) * 30)\n",
    "\n",
    "    collage = Image.new(\"RGB\", (max_width, total_height), \"white\")\n",
    "    draw = ImageDraw.Draw(collage)\n",
    "\n",
    "    try:\n",
    "        font = ImageFont.truetype(\"arial.ttf\", 20)\n",
    "    except:\n",
    "        font = ImageFont.load_default()\n",
    "\n",
    "    y_offset = 0\n",
    "    for i, img in enumerate(pil_images, 1):\n",
    "        draw.text((10, y_offset), f\"Image {i}\", fill=\"black\", font=font)\n",
    "        y_offset += 30\n",
    "        x_offset = (max_width - img.width) // 2\n",
    "        collage.paste(img, (x_offset, y_offset))\n",
    "        y_offset += img.height\n",
    "\n",
    "    buffer = io.BytesIO()\n",
    "    collage.save(buffer, format=\"PNG\")\n",
    "    return base64.b64encode(buffer.getvalue()).decode(\"utf-8\")\n",
    "\n",
    "\n",
    "def create_embeddings_and_analyze(df, output_dir):\n",
    "    \"\"\"Create embeddings using MiniLM and analyze similarities\"\"\"\n",
    "    # Initialize the model\n",
    "    model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "    # Generate embeddings for original content\n",
    "    print(\"Generating embeddings for original content...\")\n",
    "    title_embeddings = model.encode(df['Title'].tolist(), show_progress_bar=True)\n",
    "    body_embeddings = model.encode(df['Body'].tolist(), show_progress_bar=True)\n",
    "\n",
    "    # Generate embeddings for LLM responses\n",
    "    print(\"\\nGenerating embeddings for LLM responses...\")\n",
    "    response_embeddings = {\n",
    "        'zero_shot_title': model.encode(df['llm_title_response'].tolist(), show_progress_bar=True),\n",
    "        'zero_shot_body': model.encode(df['llm_body_response'].tolist(), show_progress_bar=True),\n",
    "    }\n",
    "\n",
    "    # Calculate similarities\n",
    "    similarities = {\n",
    "        'title': {},\n",
    "        'body': {}\n",
    "    }\n",
    "\n",
    "    # Calculate similarities\n",
    "    similarities['title']['zero_shot'] = np.diagonal(\n",
    "        cosine_similarity(title_embeddings, response_embeddings['zero_shot_title'])\n",
    "    )\n",
    "    similarities['body']['zero_shot'] = np.diagonal(\n",
    "        cosine_similarity(body_embeddings, response_embeddings['zero_shot_body'])\n",
    "    )\n",
    "\n",
    "    # Add similarity scores to dataframe\n",
    "    df['similarity_title'] = similarities['title']['zero_shot']\n",
    "    df['similarity_body'] = similarities['body']['zero_shot']\n",
    "\n",
    "    # Save embeddings\n",
    "    np.save(output_dir / 'similarity_analysis' / 'title_embeddings.npy', title_embeddings)\n",
    "    np.save(output_dir / 'similarity_analysis' / 'body_embeddings.npy', body_embeddings)\n",
    "\n",
    "    return df, similarities\n",
    "\n",
    "\n",
    "def analyze_similarities(similarities, output_dir):\n",
    "    \"\"\"Analyze and visualize similarity distributions\"\"\"\n",
    "    categories = {\n",
    "        'Very High': (0.8, 1.0),\n",
    "        'High': (0.6, 0.8),\n",
    "        'Moderate': (0.4, 0.6),\n",
    "        'Low': (0.2, 0.4),\n",
    "        'Very Low': (0.0, 0.2)\n",
    "    }\n",
    "\n",
    "    results = {\n",
    "        'title': {},\n",
    "        'body': {}\n",
    "    }\n",
    "\n",
    "    # Create figures for each type\n",
    "    for response_category in ['title', 'body']:\n",
    "        fig, ax = plt.subplots(figsize=(10, 5))\n",
    "        scores = similarities[response_category]['zero_shot']\n",
    "\n",
    "        stats = {\n",
    "            'mean': np.mean(scores),\n",
    "            'median': np.median(scores),\n",
    "            'std': np.std(scores),\n",
    "            'min': np.min(scores),\n",
    "            'max': np.max(scores)\n",
    "        }\n",
    "\n",
    "        distribution = {}\n",
    "        for category, (low, high) in categories.items():\n",
    "            count = np.sum((scores >= low) & (scores < high))\n",
    "            percentage = (count / len(scores)) * 100\n",
    "            distribution[category] = percentage\n",
    "\n",
    "        results[response_category]['zero_shot'] = {\n",
    "            'statistics': stats,\n",
    "            'distribution': distribution\n",
    "        }\n",
    "\n",
    "        sns.histplot(scores, bins=30, ax=ax)\n",
    "        ax.set_title(f'Similarity Distribution for {response_category.title()}')\n",
    "        ax.set_xlabel('Similarity Score')\n",
    "        ax.set_ylabel('Count')\n",
    "\n",
    "        for category, (low, high) in categories.items():\n",
    "            if low > 0:\n",
    "                ax.axvline(x=low, color='r', linestyle='--', alpha=0.3)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(output_dir / 'similarity_analysis' / f'similarity_distribution_{response_category}.png')\n",
    "        plt.close()\n",
    "\n",
    "    return results\n",
    "\n",
    "def process_with_similarity(model_name, df, output_dir):\n",
    "    \"\"\"Process results with similarity analysis\"\"\"\n",
    "    # Create embeddings and analyze similarities\n",
    "    print(f\"\\nAnalyzing similarities for {model_name}...\")\n",
    "    df_with_similarities, similarities = create_embeddings_and_analyze(df, output_dir)\n",
    "\n",
    "    # Analyze and visualize results\n",
    "    analysis_results = analyze_similarities(similarities, output_dir)\n",
    "\n",
    "    # Save results\n",
    "    output_file = output_dir / 'similarity_analysis' / f'responses_with_similarities.csv'\n",
    "    df_with_similarities.to_csv(output_file, index=False)\n",
    "\n",
    "    # Save analysis results\n",
    "    with open(output_dir / 'similarity_analysis' / f'similarity_analysis_results.json', 'w') as f:\n",
    "        json.dump(analysis_results, f, indent=4)\n",
    "\n",
    "    return df_with_similarities, analysis_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gemini Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gemini_generate_title(image_url, mode='zero-shot'):\n",
    "    \"\"\"Generate title using Gemini with different prompting techniques\"\"\"\n",
    "    try:\n",
    "        image = Image.from_bytes(requests.get(image_url).content)\n",
    "\n",
    "        if mode == 'zero-shot':\n",
    "            instruction = '''\n",
    "Context: You are an expert programmer experienced in different technology stacks. You encountered an issue while working on a project. The screenshot shows the problem but you are not given any textual content.\n",
    "Generate a Stack Overflow title that:\n",
    "1. Follows Stack Overflow guidelines\n",
    "2. Is clear and concise\n",
    "3. Summarizes the main technical issue shown\n",
    "4. Take inspiration from your trained data for stack overflow.\n",
    "\n",
    "Output Format:\n",
    "TITLE: <<Generated Title>>\n",
    "\n",
    "Make sure to start with exactly \"TITLE:\"\n",
    "'''\n",
    "        elif mode == 'chain-of-thoughts':\n",
    "            instruction = '''\n",
    "Reasoning Process for Title Generation:\n",
    "\n",
    "1. Initial Observation\n",
    "- What is immediately visible in the screenshot?\n",
    "- What IDE/tool is being used or what kind of code is shown?\n",
    "- Are there any error messages or unusual indicators?\n",
    "\n",
    "2. Problem Identification\n",
    "- What seems to be the main issue?\n",
    "- Which specific components are involved?\n",
    "- Is this a configuration, syntax, or runtime issue?\n",
    "\n",
    "3. Title Formulation\n",
    "Based on the above analysis, construct a title that:\n",
    "- Clearly summarizes the main technical issue\n",
    "- Uses relevant technical keywords\n",
    "- Is concise and specific\n",
    "- Takes inspiration from your trained data for stack overflow\n",
    "- Would be easily searchable\n",
    "\n",
    "Output Format:\n",
    "TITLE: <<Generated Title>>\n",
    "Make sure to start with exactly \"TITLE:\"\n",
    "'''\n",
    "        else:  # few-shot\n",
    "            example_image1 = Image.from_bytes(requests.get(\"https://i.sstatic.net/rUHWv1Ok.png\").content)\n",
    "            example_text1 = \"TITLE: Trying to Stack 2 Columns into one Excel\"\n",
    "            example_image2 = Image.from_bytes(requests.get(\"https://i.sstatic.net/TGFPo9Jj.png\").content)\n",
    "            example_text2 = \"TITLE: is getenv_s not part of cstdlib?\"\n",
    "\n",
    "            instruction = '''\n",
    "You are an expert software developer and Stack Overflow analyst. You are given the following examples:\n",
    "'''\n",
    "            prompt = '''\n",
    "Now generate a similar title for the given screenshot:\n",
    "Follow the pattern:\n",
    "1. Clear and concise title that summarizes the main issue\n",
    "2. Take inspiration from the example titles given\n",
    "\n",
    "Output Format:\n",
    "TITLE: <<Generated Title>>\n",
    "Make sure to start with exactly \"TITLE:\"\n",
    "'''\n",
    "            contents = [instruction, example_image1, example_text1, example_image2, example_text2, image, prompt]\n",
    "\n",
    "        if mode != 'few-shot':\n",
    "            contents = [instruction, image]\n",
    "\n",
    "        generation_config = GenerationConfig(\n",
    "            temperature=0,\n",
    "            top_p=0.8,\n",
    "            top_k=40,\n",
    "            candidate_count=1,\n",
    "            max_output_tokens=2048,\n",
    "        )\n",
    "\n",
    "        response = text_model.generate_content(\n",
    "            contents,\n",
    "            generation_config=generation_config,\n",
    "            stream=True,\n",
    "        )\n",
    "\n",
    "        result = ''\n",
    "        for r in response:\n",
    "            result += r.text\n",
    "\n",
    "        if \"TITLE:\" in result:\n",
    "            return result.split(\"TITLE:\")[1].strip()\n",
    "        return result\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing with Gemini: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def gemini_generate_body(image_url, mode='zero-shot'):\n",
    "    \"\"\"Generate body using Gemini with different prompting techniques\"\"\"\n",
    "    try:\n",
    "        image = Image.from_bytes(requests.get(image_url).content)\n",
    "\n",
    "        if mode == 'zero-shot':\n",
    "            instruction = '''\n",
    "Context: You are an expert programmer experienced in different technology stacks. You encountered an issue while working on a project. The screenshot shows the problem but you are not given any textual content.\n",
    "Generate a detailed Stack Overflow question body that:\n",
    "1. Follows Stack Overflow guidelines\n",
    "2. Includes relevant code/IDE context\n",
    "3. Clearly states the expected vs. actual behavior\n",
    "4. Take inspiration from your trained data for stack overflow.\n",
    "\n",
    "Output Format:\n",
    "BODY: <<Generated Body>>\n",
    "\n",
    "Make sure to start with exactly \"BODY:\"\n",
    "'''\n",
    "        elif mode == 'chain-of-thoughts':\n",
    "            instruction = '''\n",
    "Reasoning Process for Body Generation:\n",
    "\n",
    "1. Initial Observation\n",
    "- What is immediately visible in the screenshot?\n",
    "- What IDE/tool is being used or what kind of code is shown?\n",
    "- Are there any error messages or unusual indicators?\n",
    "\n",
    "2. Problem Identification\n",
    "- What seems to be the main issue?\n",
    "- Which specific components are involved?\n",
    "- Is this a configuration, syntax, or runtime issue?\n",
    "\n",
    "3. Context Building\n",
    "- What background or programming information is needed to understand this issue?\n",
    "- Which framework/language versions are relevant?\n",
    "- What might have led to this situation?\n",
    "\n",
    "4. Solution Attempts Analysis\n",
    "- What obvious solutions might have been tried?\n",
    "- What documentation might be relevant?\n",
    "- What troubleshooting steps would make sense?\n",
    "\n",
    "5. Question Body Formulation\n",
    "Based on the above analysis, construct a detailed body that:\n",
    "- Clearly explains the context and problem\n",
    "- Includes all relevant technical details\n",
    "- Takes inspiration from your trained data for stack overflow\n",
    "- Shows research effort and attempted solutions\n",
    "- Is specific and answerable\n",
    "\n",
    "Output Format:\n",
    "BODY: <<Generated Body>>\n",
    "Make sure to start with exactly \"BODY:\"\n",
    "'''\n",
    "        else:  # few-shot\n",
    "            example_image1 = Image.from_bytes(requests.get(\"https://i.sstatic.net/rUHWv1Ok.png\").content)\n",
    "            example_text1 = '''\n",
    "BODY: I am currently attempting to combine two columns into one but have encountered an error that prevents me from completing this task. Additionally, the data from the second column appears to be pasting incorrectly after the error messages.I would greatly appreciate any assistance with this issue.=IF(P2<>\"\",P2,INDEX($R$2:$R$5000,ROW()-COUNTA($P$2:$P$5000)))Column P and R contains formulas.\n",
    "'''\n",
    "            example_image2 = Image.from_bytes(requests.get(\"https://i.sstatic.net/TGFPo9Jj.png\").content)\n",
    "            example_text2 = '''\n",
    "BODY: C11 added new bounds-checked functions to the standard library, such as getenv_s.However, when I include <cstdlib>, I do not have std::getenv_s, only getenv_s (global namespace).cppreference has the following note:As with all bounds-checked functions, getenv_s is only guaranteed to be available if __STDC_LIB_EXT1__ is defined by the implementation and if the user defines __STDC_WANT_LIB_EXT1__ to the integer constant 1 before including <stdlib.h>.Even when I define __STDC_WANT_LIB_EXT1__ as 1, My compiler (MSVC C++23) does not find the std::getenv_s function.Isn't <cstdlib> supposed to bring every symbol of <stdlib.h> into the std namespace?\n",
    "'''\n",
    "            instruction = '''\n",
    "You are an expert software developer and Stack Overflow analyst. You are given the following examples:\n",
    "'''\n",
    "            prompt = '''\n",
    "Now generate a similar question body for the given screenshot:\n",
    "Follow the pattern:\n",
    "1. Clear and concise question body that explains the issue in detail\n",
    "2. What is the most important part of an error that can be present in the image?\n",
    "3. Take inspiration from the example bodies given\n",
    "\n",
    "Output Format:\n",
    "BODY: <<Generated Body>>\n",
    "Make sure to start with exactly \"BODY:\"\n",
    "'''\n",
    "            contents = [instruction, example_image1, example_text1, example_image2, example_text2, image, prompt]\n",
    "\n",
    "        if mode != 'few-shot':\n",
    "            contents = [instruction, image]\n",
    "\n",
    "        generation_config = GenerationConfig(\n",
    "            temperature=0,\n",
    "            top_p=0.8,\n",
    "            top_k=40,\n",
    "            candidate_count=1,\n",
    "            max_output_tokens=2048,\n",
    "        )\n",
    "\n",
    "        response = text_model.generate_content(\n",
    "            contents,\n",
    "            generation_config=generation_config,\n",
    "            stream=True,\n",
    "        )\n",
    "\n",
    "        result = ''\n",
    "        for r in response:\n",
    "            result += r.text\n",
    "\n",
    "        if \"BODY:\" in result:\n",
    "            return result.split(\"BODY:\")[1].strip()\n",
    "        return result\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing with Gemini: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def process_with_gemini(dataframe, mode='zero-shot'):\n",
    "    \"\"\"Process entire dataset using Gemini\"\"\"\n",
    "    results = []\n",
    "\n",
    "    # Create log file\n",
    "    log_file = GEMINI_DIR / f'processing_log_{mode}.txt'\n",
    "    with open(log_file, 'w') as f:\n",
    "        f.write(f\"Processing started at {time.strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "\n",
    "    for i, row in tqdm(dataframe.iterrows(), total=dataframe.shape[0], desc='Processing'):\n",
    "        print(f\"\\nProcessing Row ID: {row['Id']}\")\n",
    "\n",
    "        image_urls = [url.strip(\",\") for url in re.findall(r\"'([^']*)'\", str(row.get('ImageURLs')))]\n",
    "        title_responses = []\n",
    "        body_responses = []\n",
    "\n",
    "        for image_url in image_urls:\n",
    "            title_text = gemini_generate_title(image_url, mode)\n",
    "            body_text = gemini_generate_body(image_url, mode)\n",
    "\n",
    "            title_responses.append(title_text)\n",
    "            body_responses.append(body_text)\n",
    "\n",
    "            with open(log_file, 'a') as f:\n",
    "                f.write(f\"\\nProcessed Row ID: {row['Id']} at {time.strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "                f.write(f\"Title response: {title_text}\\n\")\n",
    "                f.write(f\"Body response: {body_text}\\n\")\n",
    "\n",
    "        results.append({\n",
    "            'Id': row['Id'],\n",
    "            'Title': row['Title'],\n",
    "            'Body': row['Body'],\n",
    "            'ImageURLs': row['ImageURLs'],\n",
    "            'llm_title_response': ' ||| '.join(title_responses),\n",
    "            'llm_body_response': ' ||| '.join(body_responses)\n",
    "        })\n",
    "\n",
    "        if len(results) % 2 == 0:\n",
    "            # Save intermediate results\n",
    "            intermediate_df = pd.DataFrame(results)\n",
    "            intermediate_file = GEMINI_DIR / f'intermediate_results_{mode}_{time.strftime(\"%Y%m%d_%H%M%S\")}.csv'\n",
    "            intermediate_df.to_csv(intermediate_file, index=False)\n",
    "            print(f\"Saved intermediate results to {intermediate_file}\")\n",
    "\n",
    "    # Save final results\n",
    "    final_df = pd.DataFrame(results)\n",
    "    final_file = GEMINI_DIR / f'llm_responses_final_{mode}.csv'\n",
    "    final_df.to_csv(final_file, index=False)\n",
    "\n",
    "    final_df_with_similarities, similarity_results = process_with_similarity(\n",
    "        'gemini',\n",
    "        final_df,\n",
    "        GEMINI_DIR\n",
    "    )\n",
    "\n",
    "    return final_df_with_similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Llama Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llama_generate_title(image_url, mode='zero-shot'):\n",
    "    \"\"\"Generate title using LLaMA with different prompting techniques\"\"\"\n",
    "    try:\n",
    "        base64_image = encode_image_to_base64(image_url)\n",
    "\n",
    "        if mode == 'zero-shot':\n",
    "            instruction = '''\n",
    "Context: You are an expert programmer experienced in different technology stacks. You encountered an issue while working on a project. The screenshot shows the problem but you are not given any textual content.\n",
    "Generate a Stack Overflow title that:\n",
    "1. Follows Stack Overflow guidelines\n",
    "2. Is clear and concise\n",
    "3. Summarizes the main technical issue shown\n",
    "4. Take inspiration from your trained data for stack overflow.\n",
    "\n",
    "Output Format:\n",
    "TITLE: <<Generated Title>>\n",
    "\n",
    "Make sure to start with exactly \"TITLE:\"\n",
    "'''\n",
    "        elif mode == 'chain-of-thoughts':\n",
    "            instruction = '''\n",
    "Reasoning Process for Title Generation:\n",
    "\n",
    "1. Initial Observation\n",
    "- What is immediately visible in the screenshot?\n",
    "- What IDE/tool is being used or what kind of code is shown?\n",
    "- Are there any error messages or unusual indicators?\n",
    "\n",
    "2. Problem Identification\n",
    "- What seems to be the main issue?\n",
    "- Which specific components are involved?\n",
    "- Is this a configuration, syntax, or runtime issue?\n",
    "\n",
    "3. Title Formulation\n",
    "Based on the above analysis, construct a title that:\n",
    "- Clearly summarizes the main technical issue\n",
    "- Uses relevant technical keywords\n",
    "- Is concise and specific\n",
    "- Takes inspiration from your trained data for stack overflow\n",
    "- Would be easily searchable\n",
    "\n",
    "Output Format:\n",
    "TITLE: <<Generated Title>>\n",
    "Make sure to start with exactly \"TITLE:\"\n",
    "'''\n",
    "        else:  # few-shot\n",
    "            instruction = '''\n",
    "You are an expert software developer and Stack Overflow analyst. You are given the following examples:\n",
    "\n",
    "Example 1:\n",
    "Title: \"Trying to Stack 2 Columns into one Excel\"\n",
    "\n",
    "Example 2:\n",
    "Title: \"is getenv_s not part of cstdlib?\"\n",
    "\n",
    "Now generate a similar title for the given screenshot:\n",
    "Follow the pattern:\n",
    "1. Clear and concise title that summarizes the main issue\n",
    "2. Take inspiration from the example titles given\n",
    "\n",
    "Output Format:\n",
    "TITLE: <<Generated Title>>\n",
    "Make sure to start with exactly \"TITLE:\"\n",
    "'''\n",
    "\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": instruction},\n",
    "                    {\"type\": \"image_url\",\n",
    "                     \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"}}\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        response = groq_client.chat.completions.create(\n",
    "            messages=messages,\n",
    "            model=\"llama-3.2-90b-vision-preview\",\n",
    "            temperature=0,\n",
    "            max_tokens=2048\n",
    "        )\n",
    "\n",
    "        result = response.choices[0].message.content\n",
    "        if \"TITLE:\" in result:\n",
    "            return result.split(\"TITLE:\")[1].strip()\n",
    "        return result\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing with LLaMA: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def llama_generate_body(image_url, mode='zero-shot'):\n",
    "    \"\"\"Generate body using LLaMA with different prompting techniques\"\"\"\n",
    "    try:\n",
    "        base64_image = encode_image_to_base64(image_url)\n",
    "\n",
    "        if mode == 'zero-shot':\n",
    "            instruction = '''\n",
    "Context: You are an expert programmer experienced in different technology stacks. You encountered an issue while working on a project. The screenshot shows the problem but you are not given any textual content.\n",
    "Generate a detailed Stack Overflow question body that:\n",
    "1. Follows Stack Overflow guidelines\n",
    "2. Includes relevant code/IDE context\n",
    "3. Clearly states the expected vs. actual behavior\n",
    "4. Take inspiration from your trained data for stack overflow.\n",
    "\n",
    "Output Format:\n",
    "BODY: <<Generated Body>>\n",
    "\n",
    "Make sure to start with exactly \"BODY:\"\n",
    "'''\n",
    "        elif mode == 'chain-of-thoughts':\n",
    "            instruction = '''\n",
    "Reasoning Process for Body Generation:\n",
    "\n",
    "1. Initial Observation\n",
    "- What is immediately visible in the screenshot?\n",
    "- What IDE/tool is being used or what kind of code is shown?\n",
    "- Are there any error messages or unusual indicators?\n",
    "\n",
    "2. Problem Identification\n",
    "- What seems to be the main issue?\n",
    "- Which specific components are involved?\n",
    "- Is this a configuration, syntax, or runtime issue?\n",
    "\n",
    "3. Context Building\n",
    "- What background or programming information is needed to understand this issue?\n",
    "- Which framework/language versions are relevant?\n",
    "- What might have led to this situation?\n",
    "\n",
    "4. Solution Attempts Analysis\n",
    "- What obvious solutions might have been tried?\n",
    "- What documentation might be relevant?\n",
    "- What troubleshooting steps would make sense?\n",
    "\n",
    "5. Question Body Formulation\n",
    "Based on the above analysis, construct a detailed body that:\n",
    "- Clearly explains the context and problem\n",
    "- Includes all relevant technical details\n",
    "- Takes inspiration from your trained data for stack overflow\n",
    "- Shows research effort and attempted solutions\n",
    "- Is specific and answerable\n",
    "\n",
    "Output Format:\n",
    "BODY: <<Generated Body>>\n",
    "Make sure to start with exactly \"BODY:\"\n",
    "'''\n",
    "        else:  # few-shot\n",
    "            instruction = '''\n",
    "You are an expert software developer and Stack Overflow analyst. You are given the following examples:\n",
    "\n",
    "Example 1:\n",
    "Body: \"I am currently attempting to combine two columns into one but have encountered an error that prevents me from completing this task. Additionally, the data from the second column appears to be pasting incorrectly after the error messages.I would greatly appreciate any assistance with this issue.=IF(P2<>\"\",P2,INDEX($R$2:$R$5000,ROW()-COUNTA($P$2:$P$5000)))Column P and R contains formulas.\"\n",
    "\n",
    "Example 2:\n",
    "Body: \"C11 added new bounds-checked functions to the standard library, such as getenv_s. However, when I include <cstdlib>, I do not have std::getenv_s, only getenv_s (global namespace). cppreference has the following note: As with all bounds-checked functions, getenv_s is only guaranteed to be available if __STDC_LIB_EXT1__ is defined by the implementation and if the user defines __STDC_WANT_LIB_EXT1__ to the integer constant 1 before including <stdlib.h>. Even when I define __STDC_WANT_LIB_EXT1__ as 1, My compiler (MSVC C++23) does not find the std::getenv_s function. Isn't <cstdlib> supposed to bring every symbol of <stdlib.h> into the std namespace?\"\n",
    "\n",
    "Now generate a similar question body for the given screenshot:\n",
    "Follow the pattern:\n",
    "1. Clear and concise question body that explains the issue in detail\n",
    "2. What is the most important part of an error that can be present in the image?\n",
    "3. Take inspiration from the example bodies given\n",
    "\n",
    "Output Format:\n",
    "BODY: <<Generated Body>>\n",
    "Make sure to start with exactly \"BODY:\"\n",
    "'''\n",
    "\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": instruction},\n",
    "                    {\"type\": \"image_url\",\n",
    "                     \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"}}\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        response = groq_client.chat.completions.create(\n",
    "            messages=messages,\n",
    "            model=\"llama-3.2-90b-vision-preview\",\n",
    "            temperature=0,\n",
    "            max_tokens=4096\n",
    "        )\n",
    "\n",
    "        result = response.choices[0].message.content\n",
    "        if \"BODY:\" in result:\n",
    "            return result.split(\"BODY:\")[1].strip()\n",
    "        return result\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing with LLaMA: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def process_with_llama(dataframe, mode='zero-shot'):\n",
    "    \"\"\"Process entire dataset using LLaMA\"\"\"\n",
    "    results = []\n",
    "\n",
    "    # Create log file\n",
    "    log_file = LLAMA_DIR / f'processing_log_{mode}.txt'\n",
    "    with open(log_file, 'w') as f:\n",
    "        f.write(f\"Processing started at {time.strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "\n",
    "    for i, row in tqdm(dataframe.iterrows(), total=dataframe.shape[0], desc='Processing'):\n",
    "        print(f\"\\nProcessing Row ID: {row['Id']}\")\n",
    "\n",
    "        image_urls = [url.strip(\",\") for url in re.findall(r\"'([^']*)'\", str(row.get('ImageURLs')))]\n",
    "        title_responses = []\n",
    "        body_responses = []\n",
    "\n",
    "        for image_url in image_urls:\n",
    "            title_text = llama_generate_title(image_url, mode)\n",
    "            body_text = llama_generate_body(image_url, mode)\n",
    "\n",
    "            title_responses.append(title_text)\n",
    "            body_responses.append(body_text)\n",
    "\n",
    "            with open(log_file, 'a') as f:\n",
    "                f.write(f\"\\nProcessed Row ID: {row['Id']} at {time.strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "                f.write(f\"Title response: {title_text}\\n\")\n",
    "                f.write(f\"Body response: {body_text}\\n\")\n",
    "\n",
    "        results.append({\n",
    "            'Id': row['Id'],\n",
    "            'Title': row['Title'],\n",
    "            'Body': row['Body'],\n",
    "            'ImageURLs': row['ImageURLs'],\n",
    "            'llm_title_response': ' ||| '.join(title_responses),\n",
    "            'llm_body_response': ' ||| '.join(body_responses)\n",
    "        })\n",
    "\n",
    "        if len(results) % 2 == 0:\n",
    "            # Save intermediate results\n",
    "            intermediate_df = pd.DataFrame(results)\n",
    "            intermediate_file = LLAMA_DIR / f'intermediate_results_{mode}_{time.strftime(\"%Y%m%d_%H%M%S\")}.csv'\n",
    "            intermediate_df.to_csv(intermediate_file, index=False)\n",
    "            print(f\"Saved intermediate results to {intermediate_file}\")\n",
    "\n",
    "    # Save final results\n",
    "    final_df = pd.DataFrame(results)\n",
    "    final_file = LLAMA_DIR / f'llm_responses_final_{mode}.csv'\n",
    "    final_df.to_csv(final_file, index=False)\n",
    "\n",
    "    final_df_with_similarities, similarity_results = process_with_similarity(\n",
    "        'llama',\n",
    "        final_df,\n",
    "        LLAMA_DIR\n",
    "    )\n",
    "\n",
    "    return final_df_with_similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt_generate_title(image_url, mode='zero-shot'):\n",
    "    \"\"\"Generate title using GPT-4 Vision with different prompting techniques\"\"\"\n",
    "    try:\n",
    "        base64_image = encode_image_to_base64(image_url)\n",
    "\n",
    "        if mode == 'zero-shot':\n",
    "            instruction = '''\n",
    "Context: You are an expert programmer experienced in different technology stacks. You encountered an issue while working on a project. The screenshot shows the problem but you are not given any textual content.\n",
    "Generate a Stack Overflow title that:\n",
    "1. Follows Stack Overflow guidelines\n",
    "2. Is clear and concise\n",
    "3. Summarizes the main technical issue shown\n",
    "4. Take inspiration from your trained data for stack overflow.\n",
    "\n",
    "Output Format:\n",
    "TITLE: <<Generated Title>>\n",
    "\n",
    "Make sure to start with exactly \"TITLE:\"\n",
    "'''\n",
    "        elif mode == 'chain-of-thoughts':\n",
    "            instruction = '''\n",
    "Let's think about this step by step:\n",
    "\n",
    "1. Initial Visual Analysis\n",
    "- What are we seeing in the screenshot?\n",
    "- What IDE/tool/interface is being used?\n",
    "- Are there any error messages or warnings?\n",
    "\n",
    "2. Technical Context\n",
    "- What programming language/framework is involved?\n",
    "- What specific components or features are we working with?\n",
    "- Is there any configuration or setup visible?\n",
    "\n",
    "3. Problem Pattern Recognition\n",
    "- What type of issue is this (syntax error, runtime error, unexpected behavior)?\n",
    "- What specific error messages or unexpected outputs are shown?\n",
    "- What seems to be the root cause based on the visual evidence?\n",
    "\n",
    "4. Title Construction\n",
    "Now, based on this analysis, construct a title that:\n",
    "- Clearly identifies the main technical issue\n",
    "- Includes relevant technical keywords\n",
    "- Is concise yet informative\n",
    "- Follows Stack Overflow best practices\n",
    "\n",
    "Output Format:\n",
    "TITLE: <<Generated Title>>\n",
    "Make sure to start with exactly \"TITLE:\"\n",
    "'''\n",
    "        else:  # few-shot\n",
    "            instruction = '''\n",
    "You are an expert software developer and Stack Overflow analyst. Here are two examples of effective Stack Overflow titles for reference:\n",
    "\n",
    "Example 1: \"Trying to Stack 2 Columns into one Excel\"\n",
    "- Notice how it clearly states the action and the specific Excel operation\n",
    "\n",
    "Example 2: \"is getenv_s not part of cstdlib?\"\n",
    "- Observe how it specifically names the function and library in question\n",
    "\n",
    "Now, looking at the provided screenshot:\n",
    "1. Follow a similar pattern of clarity and specificity\n",
    "2. Focus on the main technical issue shown\n",
    "3. Use relevant technical terms from the image\n",
    "\n",
    "Output Format:\n",
    "TITLE: <<Generated Title>>\n",
    "Make sure to start with exactly \"TITLE:\"\n",
    "'''\n",
    "\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": instruction\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                            \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt4o\",\n",
    "            messages=messages,\n",
    "            max_tokens=2048,\n",
    "            temperature=0\n",
    "        )\n",
    "\n",
    "        result = response.choices[0].message.content\n",
    "        if \"TITLE:\" in result:\n",
    "            return result.split(\"TITLE:\")[1].strip()\n",
    "        return result\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing with GPT: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def gpt_generate_body(image_url, mode='zero-shot'):\n",
    "    \"\"\"Generate body using GPT-4 Vision with different prompting techniques\"\"\"\n",
    "    try:\n",
    "        base64_image = encode_image_to_base64(image_url)\n",
    "\n",
    "        if mode == 'zero-shot':\n",
    "            instruction = '''\n",
    "Context: You are an expert programmer experienced in different technology stacks. You encountered an issue while working on a project. The screenshot shows the problem but you are not given any textual content.\n",
    "Generate a detailed Stack Overflow question body that:\n",
    "1. Follows Stack Overflow guidelines\n",
    "2. Includes relevant code/IDE context\n",
    "3. Clearly states the expected vs. actual behavior\n",
    "4. Take inspiration from your trained data for stack overflow.\n",
    "\n",
    "Output Format:\n",
    "BODY: <<Generated Body>>\n",
    "\n",
    "Make sure to start with exactly \"BODY:\"\n",
    "'''\n",
    "        elif mode == 'chain-of-thoughts':\n",
    "            instruction = '''\n",
    "Let's analyze this systematically:\n",
    "\n",
    "1. Visual Analysis\n",
    "- What do we see in the screenshot?\n",
    "- What development environment or tool is shown?\n",
    "- What UI elements or code snippets are visible?\n",
    "\n",
    "2. Technical Context Identification\n",
    "- Which technologies/frameworks are involved?\n",
    "- What version or environment details are relevant?\n",
    "- What setup or configuration is implied?\n",
    "\n",
    "3. Problem Description Formation\n",
    "- What is the main issue or error shown?\n",
    "- What were the expected and actual outcomes?\n",
    "- What relevant code or configuration is visible?\n",
    "\n",
    "4. Attempt Documentation\n",
    "- What approaches might have already been tried?\n",
    "- What common solutions would need to be ruled out?\n",
    "- What troubleshooting steps are implied?\n",
    "\n",
    "5. Question Formulation\n",
    "Based on this analysis, create a body that:\n",
    "- Clearly describes the technical context\n",
    "- Documents the specific issue\n",
    "- Shows research effort\n",
    "- Includes relevant code/configuration\n",
    "- Asks a specific, answerable question\n",
    "\n",
    "Output Format:\n",
    "BODY: <<Generated Body>>\n",
    "Make sure to start with exactly \"BODY:\"\n",
    "'''\n",
    "        else:  # few-shot\n",
    "            instruction = '''\n",
    "You are an expert software developer and Stack Overflow analyst. Here are two examples of effective question bodies:\n",
    "\n",
    "Example 1:\n",
    "\"I am currently attempting to combine two columns into one but have encountered an error that prevents me from completing this task. Additionally, the data from the second column appears to be pasting incorrectly after the error messages. I would greatly appreciate any assistance with this issue. =IF(P2<>\"\",P2,INDEX($R$2:$R$5000,ROW()-COUNTA($P$2:$P$5000))) Column P and R contains formulas.\"\n",
    "\n",
    "Example 2:\n",
    "\"C11 added new bounds-checked functions to the standard library, such as getenv_s. However, when I include <cstdlib>, I do not have std::getenv_s, only getenv_s (global namespace). cppreference has the following note: As with all bounds-checked functions, getenv_s is only guaranteed to be available if __STDC_LIB_EXT1__ is defined by the implementation and if the user defines __STDC_WANT_LIB_EXT1__ to the integer constant 1 before including <stdlib.h>. Even when I define __STDC_WANT_LIB_EXT1__ as 1, My compiler (MSVC C++23) does not find the std::getenv_s function. Isn't <cstdlib> supposed to bring every symbol of <stdlib.h> into the std namespace?\"\n",
    "\n",
    "Now, create a similar detailed body for the issue shown in the screenshot:\n",
    "1. Follow the pattern of clear problem description\n",
    "2. Include relevant technical details\n",
    "3. Show attempted solutions if visible\n",
    "4. Ask clear, specific questions\n",
    "\n",
    "Output Format:\n",
    "BODY: <<Generated Body>>\n",
    "Make sure to start with exactly \"BODY:\"\n",
    "'''\n",
    "\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": instruction\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                            \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt4o\",\n",
    "            messages=messages,\n",
    "            max_tokens=4096,\n",
    "            temperature=0\n",
    "        )\n",
    "\n",
    "        result = response.choices[0].message.content\n",
    "        if \"BODY:\" in result:\n",
    "            return result.split(\"BODY:\")[1].strip()\n",
    "        return result\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing with GPT: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def process_with_gpt(dataframe, mode='zero-shot'):\n",
    "    \"\"\"Process entire dataset using GPT-4 Vision\"\"\"\n",
    "    results = []\n",
    "\n",
    "    # Create log file\n",
    "    log_file = GPT_DIR / f'processing_log_{mode}.txt'\n",
    "    with open(log_file, 'w') as f:\n",
    "        f.write(f\"Processing started at {time.strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "\n",
    "    for i, row in tqdm(dataframe.iterrows(), total=dataframe.shape[0], desc='Processing'):\n",
    "        print(f\"\\nProcessing Row ID: {row['Id']}\")\n",
    "\n",
    "        image_urls = [url.strip(\",\") for url in re.findall(r\"'([^']*)'\", str(row.get('ImageURLs')))]\n",
    "        title_responses = []\n",
    "        body_responses = []\n",
    "\n",
    "        for image_url in image_urls:\n",
    "            title_text = gpt_generate_title(image_url, mode)\n",
    "            body_text = gpt_generate_body(image_url, mode)\n",
    "\n",
    "            title_responses.append(title_text)\n",
    "            body_responses.append(body_text)\n",
    "\n",
    "            with open(log_file, 'a') as f:\n",
    "                f.write(f\"\\nProcessed Row ID: {row['Id']} at {time.strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "                f.write(f\"Title response: {title_text}\\n\")\n",
    "                f.write(f\"Body response: {body_text}\\n\")\n",
    "\n",
    "        results.append({\n",
    "            'Id': row['Id'],\n",
    "            'Title': row['Title'],\n",
    "            'Body': row['Body'],\n",
    "            'ImageURLs': row['ImageURLs'],\n",
    "            'llm_title_response': ' ||| '.join(title_responses),\n",
    "            'llm_body_response': ' ||| '.join(body_responses)\n",
    "        })\n",
    "\n",
    "        if len(results) % 2 == 0:\n",
    "            # Save intermediate results\n",
    "            intermediate_df = pd.DataFrame(results)\n",
    "            intermediate_file = GPT_DIR / f'intermediate_results_{mode}_{time.strftime(\"%Y%m%d_%H%M%S\")}.csv'\n",
    "            intermediate_df.to_csv(intermediate_file, index=False)\n",
    "            print(f\"Saved intermediate results to {intermediate_file}\")\n",
    "\n",
    "    # Save final results\n",
    "    final_df = pd.DataFrame(results)\n",
    "    final_file = GPT_DIR / f'llm_responses_final_{mode}.csv'\n",
    "    final_df.to_csv(final_file, index=False)\n",
    "\n",
    "    final_df_with_similarities, similarity_results = process_with_similarity(\n",
    "        'gpt',\n",
    "        final_df,\n",
    "        GPT_DIR\n",
    "    )\n",
    "\n",
    "    return final_df_with_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Load Dataset and Main Processing Pipeline\n",
    "# Load dataset\n",
    "dataset = pd.read_csv('Data/filtered_data_matched.csv')\n",
    "print(f\"Loaded dataset with {len(dataset)} rows\")\n",
    "\n",
    "def process_all_models():\n",
    "    \"\"\"Process dataset with all models and prompting techniques, including similarity analysis\"\"\"\n",
    "\n",
    "    # Dictionary to store all results\n",
    "    all_results = {\n",
    "        'gemini': {},\n",
    "        'llama': {},\n",
    "        'gpt': {}\n",
    "    }\n",
    "\n",
    "    prompting_techniques = ['zero-shot', 'few-shot', 'chain-of-thoughts']\n",
    "\n",
    "    for technique in prompting_techniques:\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Processing with {technique} prompting\")\n",
    "        print(f\"{'='*50}\")\n",
    "\n",
    "        # Process with Gemini\n",
    "        print(\"\\nStarting Gemini processing...\")\n",
    "        gemini_results = process_with_gemini(dataset, mode=technique)\n",
    "        all_results['gemini'][technique] = {\n",
    "            'data': gemini_results,\n",
    "            'dir': GEMINI_DIR\n",
    "        }\n",
    "        print(f\"Completed Gemini processing with similarity analysis\")\n",
    "\n",
    "        # Process with LLaMA\n",
    "        print(\"\\nStarting LLaMA processing...\")\n",
    "        llama_results = process_with_llama(dataset, mode=technique)\n",
    "        all_results['llama'][technique] = {\n",
    "            'data': llama_results,\n",
    "            'dir': LLAMA_DIR\n",
    "        }\n",
    "        print(f\"Completed LLaMA processing with similarity analysis\")\n",
    "\n",
    "        # Process with GPT\n",
    "        print(\"\\nStarting GPT processing...\")\n",
    "        gpt_results = process_with_gpt(dataset, mode=technique)\n",
    "        all_results['gpt'][technique] = {\n",
    "            'data': gpt_results,\n",
    "            'dir': GPT_DIR\n",
    "        }\n",
    "        print(f\"Completed GPT processing with similarity analysis\")\n",
    "\n",
    "        print(f\"\\nCompleted {technique} processing for all models\")\n",
    "\n",
    "        # Generate comparative analysis\n",
    "        compare_model_similarities(\n",
    "            technique,\n",
    "            gemini_results,\n",
    "            llama_results,\n",
    "            gpt_results,\n",
    "            OUTPUT_DIR / f'comparative_analysis_{technique}'\n",
    "        )\n",
    "\n",
    "    return all_results\n",
    "\n",
    "def compare_model_similarities(technique, gemini_df, llama_df, gpt_df, output_dir):\n",
    "    \"\"\"Compare similarity scores across models\"\"\"\n",
    "    output_dir = pathlib.Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Prepare comparison data\n",
    "    comparison_data = {\n",
    "        'gemini': {\n",
    "            'title': gemini_df['similarity_title'],\n",
    "            'body': gemini_df['similarity_body']\n",
    "        },\n",
    "        'llama': {\n",
    "            'title': llama_df['similarity_title'],\n",
    "            'body': llama_df['similarity_body']\n",
    "        },\n",
    "        'gpt': {\n",
    "            'title': gpt_df['similarity_title'],\n",
    "            'body': gpt_df['similarity_body']\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Create comparison plots\n",
    "    for content_type in ['title', 'body']:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        for model in ['gemini', 'llama', 'gpt']:\n",
    "            sns.kdeplot(\n",
    "                data=comparison_data[model][content_type],\n",
    "                label=model.upper()\n",
    "            )\n",
    "\n",
    "        plt.title(f'Similarity Score Distribution Comparison - {content_type.title()} ({technique})')\n",
    "        plt.xlabel('Similarity Score')\n",
    "        plt.ylabel('Density')\n",
    "        plt.legend()\n",
    "        plt.savefig(output_dir / f'similarity_comparison_{content_type}.png')\n",
    "        plt.close()\n",
    "\n",
    "    # Calculate summary statistics\n",
    "    summary_stats = {\n",
    "        'technique': technique,\n",
    "        'models': {}\n",
    "    }\n",
    "\n",
    "    for model in ['gemini', 'llama', 'gpt']:\n",
    "        summary_stats['models'][model] = {\n",
    "            'title': {\n",
    "                'mean': np.mean(comparison_data[model]['title']),\n",
    "                'median': np.median(comparison_data[model]['title']),\n",
    "                'std': np.std(comparison_data[model]['title'])\n",
    "            },\n",
    "            'body': {\n",
    "                'mean': np.mean(comparison_data[model]['body']),\n",
    "                'median': np.median(comparison_data[model]['body']),\n",
    "                'std': np.std(comparison_data[model]['body'])\n",
    "            }\n",
    "        }\n",
    "\n",
    "    # Save summary statistics\n",
    "    with open(output_dir / 'comparison_summary.json', 'w') as f:\n",
    "        json.dump(summary_stats, f, indent=4)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    results = process_all_models()\n",
    "    print(\"\\nProcessing completed for all models with similarity analysis\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
